{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "95edd0c6-b44e-40d6-9e9c-48f42ddd5207",
      "metadata": {
        "id": "95edd0c6-b44e-40d6-9e9c-48f42ddd5207"
      },
      "source": [
        "# 0. [OPTIONAL] Installing course dependencies\n",
        "\n",
        "These are dependencies for the whole course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ae1d575-f278-450f-aa6f-d99e075a79e5",
      "metadata": {
        "id": "7ae1d575-f278-450f-aa6f-d99e075a79e5"
      },
      "outputs": [],
      "source": [
        "!pip install -r ../requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "158874a2-fb2f-4429-8c13-01457e9767b4",
      "metadata": {
        "id": "158874a2-fb2f-4429-8c13-01457e9767b4"
      },
      "source": [
        "You may skip the next block for now. You will need `ffmpeg` on week 12."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f337db2-7f6a-4520-b51e-f38f064ed599",
      "metadata": {
        "id": "4f337db2-7f6a-4520-b51e-f38f064ed599"
      },
      "outputs": [],
      "source": [
        "# !conda update -y base conda\n",
        "!conda install -c conda-forge ffmpeg -y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06c2f0dd-1d63-412c-ae93-2f012c3d8f0c",
      "metadata": {
        "id": "06c2f0dd-1d63-412c-ae93-2f012c3d8f0c"
      },
      "source": [
        "Run the next cell if you want to download embedding model, but this is not required during this lab. You can do it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74fa01d2-dd4d-48d4-a27b-9ae610d9e7ab",
      "metadata": {
        "id": "74fa01d2-dd4d-48d4-a27b-9ae610d9e7ab"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_trf_distilbertbaseuncased_lg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ef7bedc-d559-437e-b106-12c860acfbab",
      "metadata": {
        "id": "4ef7bedc-d559-437e-b106-12c860acfbab"
      },
      "source": [
        "# 1. Touching the Internet\n",
        "\n",
        "Solve the following task.\n",
        "1. Download [this page](https://raw.githubusercontent.com/YusufRoshdy/information-retrieval/main/datasets/facts.txt)\n",
        "2. Save it to the file with the **unique** name derived from the URL. NB File with another URL should not be save into the file with this name. E.g. [this file](https://github.com/YusufRoshdy/information-retrieval/blob/main/datasets/facts.txt) is another file with another content!\n",
        "\n",
        "Hints:\n",
        "- [requests](https://docs.python-requests.org/en/latest/) library is cool.\n",
        "- [hashlib](https://docs.python.org/3/library/hashlib.html) may help with computing hash strings.\n",
        "- when you download and save the data, don't try to encode and decode it. Use binary format when working with streams and files. <span style=\"color:red\">Discuss with your TA which encodings you know and how they differ</span>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "639fb2d7-d577-4ae6-beb4-2487213024cf",
      "metadata": {
        "id": "639fb2d7-d577-4ae6-beb4-2487213024cf"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url1 = \"https://raw.githubusercontent.com/YusufRoshdy/information-retrieval/main/datasets/facts.txt\"\n",
        "url2 = \"https://github.com/YusufRoshdy/information-retrieval/blob/main/datasets/facts.txt\"\n",
        "\n",
        "# TODO: download and save these documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FtOyYrM_k70s",
      "metadata": {
        "id": "FtOyYrM_k70s"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import hashlib\n",
        "\n",
        "url1 = \"https://raw.githubusercontent.com/YusufRoshdy/information-retrieval/main/datasets/facts.txt\"\n",
        "\n",
        "response = requests.get(url1)\n",
        "\n",
        "response.headers['Content-Type']\n",
        "if response.status_code == 200:\n",
        "  filename = hashlib.sha256(url1.encode()).hexdigest()\n",
        "  filename = f'{filename}.txt'\n",
        "\n",
        "  with open (filename, 'wb') as file:\n",
        "    file.write(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U3UftsOSiF-w",
      "metadata": {
        "id": "U3UftsOSiF-w"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import hashlib\n",
        "\n",
        "url2 = \"https://github.com/YusufRoshdy/information-retrieval/blob/main/datasets/facts.txt\"\n",
        "\n",
        "response = requests.get(url2)\n",
        "\n",
        "response.headers['Content-Type']\n",
        "if response.status_code == 200:\n",
        "  filename = hashlib.sha256(url2.encode()).hexdigest()\n",
        "  filename = f'{filename}.txt'\n",
        "\n",
        "  with open (filename, 'wb') as file:\n",
        "    file.write(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7601aaf-3534-42cd-bb33-665d2d92c79d",
      "metadata": {
        "id": "c7601aaf-3534-42cd-bb33-665d2d92c79d"
      },
      "source": [
        "# 2. Parsing different formats\n",
        "\n",
        "Most probably, if you meet something in the Internet, this is one of: binary, plain text, XML, or json. XML then splits into xHTML, RSS, Atom, SOAP, XML-RPC, ... . Your task is to learn, how to process different formats.\n",
        "\n",
        "## 2.1. JSON\n",
        "\n",
        "In [the given file](https://raw.githubusercontent.com/YusufRoshdy/information-retrieval/main/datasets/unique_videos.json) there is valid json. Parse this file and print all video URLs, which have `computer science` tag. Use built-in features of `requests`, or just a `json` library ([ref](https://docs.python.org/3/library/json.html)).\n",
        "\n",
        "Hint:\n",
        "- if the file has issues with parsing read about [the difference](https://stackoverflow.com/questions/57152985/what-is-the-difference-between-utf-8-and-utf-8-sig)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "628c2c18-b896-40f9-bac9-2fefc5027da1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "628c2c18-b896-40f9-bac9-2fefc5027da1",
        "outputId": "3f89d214-6d06-4232-f484-72975002b766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://www.tech_tutorialhub.com/lessons/video_1\n",
            "http://www.coding_learnnow.com/topics/video_2\n",
            "http://www.coding_learnnow.com/courses/video_3\n",
            "http://www.coding_videostore.com/courses/video_4\n",
            "http://www.cs_tutorialhub.com/topics/video_5\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/YusufRoshdy/information-retrieval/main/datasets/unique_videos.json\"\n",
        "\n",
        "json_took = requests.get(url)\n",
        "formatt = json_took.json()\n",
        "videos = formatt.get('videos')\n",
        "cs_list = []\n",
        "for video in videos:\n",
        "  if 'computer science' in video.get('tags'):\n",
        "    cs_list.append(video.get('url'))\n",
        "\n",
        "for ur in cs_list:\n",
        "  print(ur)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a97530a0-46d4-47e3-a7bb-ca479680007d",
      "metadata": {
        "id": "a97530a0-46d4-47e3-a7bb-ca479680007d"
      },
      "source": [
        "## 2.2. HTML\n",
        "\n",
        "For a given StackExchange answer extract logins of the contributors (who asked and who answered) with votes. [bs4](https://beautiful-soup-4.readthedocs.io/en/latest/) will help you to do the job.\n",
        "\n",
        "I can recommend to use CSS or XPath selectors. `div` elements with `post-layout` class represent answers. Inside there are `div` with `votecell` class stroring votes number and `div` with class `user-details` storing user info. My personal recommendation is to use `css selectors`, which are [documented here](https://beautiful-soup-4.readthedocs.io/en/latest/#css-selectors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e67db473-a8f0-414c-adbc-ce0e9e4710bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e67db473-a8f0-414c-adbc-ce0e9e4710bc",
        "metadata": {},
        "outputId": "82c076ed-a3fa-40ab-aecd-8dd6b425a199"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bs4'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://math.stackexchange.com/questions/411486/\u001b[39m\u001b[38;5;124m\"\u001b[39m\\\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munderstanding-the-singular-value-decomposition-svd\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(url)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://math.stackexchange.com/questions/411486/\"\\\n",
        "        \"understanding-the-singular-value-decomposition-svd\"\n",
        "print(url)\n",
        "\n",
        "# TODO. Your code here should parse HTML source page and find contributors of the repository.\n",
        "\n",
        "parsed_page = requests.get(url)\n",
        "\n",
        "soup = BeautifulSoup(parsed_page.content, 'html.parser')\n",
        "# print(soup.prettify())\n",
        "answer_elements = soup.select('div.post-layout')\n",
        "votes = []\n",
        "user_details = []\n",
        "for answer in answer_elements:\n",
        "  votes_element = answer.select_one('div.votecell')\n",
        "  votes.append(votes_element.get_text(strip=True))\n",
        "  user_info = answer.select_one('div.user-details')\n",
        "  user_details.append(user_info.get_text(strip=True))\n",
        "for index, _ in enumerate(votes):\n",
        "  print(f'{user_details[index]} \\t: {votes[index]}')\n",
        "# print(answer_elements)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6708766b-0db3-4062-87a1-9ba96c60440b",
      "metadata": {
        "id": "6708766b-0db3-4062-87a1-9ba96c60440b"
      },
      "source": [
        "# 2.3. RSS feed\n",
        "\n",
        "A lot of information is already organized in typed XML documents. Podcasts, for example, are just RSS feed. Parse [the feed of this podcast](https://waylonwalker.com/rss.xml) and print out:\n",
        "- the number of episodes\n",
        "- the length of the time span between the first and the last episodes (in days).\n",
        "\n",
        "Use [`feedparser` library for this](https://waylonwalker.com/parsing-rss-python/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2090f810-d706-4bb2-8c85-d485a48432a1",
      "metadata": {
        "id": "2090f810-d706-4bb2-8c85-d485a48432a1"
      },
      "outputs": [],
      "source": [
        "import feedparser\n",
        "rss = 'https://waylonwalker.com/rss.xml'\n",
        "feedparser.parse(rss)\n",
        "\n",
        "# TODO: complete the code to compute the time span of all the episodes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a7a63b1-c106-4a13-8e55-9240e9c8418f",
      "metadata": {
        "id": "3a7a63b1-c106-4a13-8e55-9240e9c8418f"
      },
      "source": [
        "# 3. [EXTRA TASK] Solving simple information retrieval task\n",
        "\n",
        "According to the name, `information retrieval` is the discipline, which helps retrieves information (from unstructured sources). Thus, we will retrieve some information from [this news article](https://www.nbcnews.com/health/health-news/organ-transplant-work-us-revamps-organ-donation-system-rcna76103). Your task is to write a code, which will answer the question: **How many people die every day in the US waiting for a transplant?** Write flexible enough code. Test yourself by changing the link to [this one](https://www.kidney.org/news/newsroom/factsheets/Organ-Donation-and-Transplantation-Stats)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7660c706-371b-4050-aede-e4b3e4014ce1",
      "metadata": {
        "id": "7660c706-371b-4050-aede-e4b3e4014ce1"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "url = 'https://www.nbcnews.com/health/health-news/organ-transplant-work-us-revamps-organ-donation-system-rcna76103'\n",
        "url = 'https://www.kidney.org/news/newsroom/factsheets/Organ-Donation-and-Transplantation-Stats'\n",
        "# url = 'https://www.bbc.com/news/world-us-canada-59944889' # One more link\n",
        "\n",
        "question = 'How many people die every day in the US waiting for a transplant?'\n",
        "\n",
        "# TODO. Impress me!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
